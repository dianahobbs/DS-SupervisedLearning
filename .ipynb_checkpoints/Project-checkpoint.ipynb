{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d254a2-093d-478b-b531-e4f3ec1d4b94",
   "metadata": {},
   "source": [
    "# Alzheimer Disease: Predicting Cognitive Decline Using Neuroimaging Biomarkers\n",
    "\n",
    "## Introduction - What is the paper about? What drew you to it? What are you setting out to discover? \n",
    "\n",
    "Accumulation of ß-amyloid (Aß)plaques, tau-containing neurofibrillary tangles, and progressive neuronal atrophy are the hallmark neuroanatomical biomarkers of Alzheimer Disease (AD), and these progressive changes emerge up to two decades prior to decline in cognition. Following the Aß, tau, and neurodegenerative (ATN) framework, we will investigate the relationship between AD biomarkers and cognitive decline in older adults.\n",
    "\n",
    "***Determine the problem and select a perfomance metric to determine success. (determine what the problem actually is - select performance metric upfront (is accuracy good enough or are false negatives a bad bad thing))**\n",
    " \n",
    "\n",
    "## The Data Analysis Pipeline - how did you address each of the steps in the pipeline? \n",
    "\n",
    "choosing machine learning - supervised \n",
    "\n",
    "### 1. Data: OASIS and ADNI\n",
    "Data were provided by the Open Access Series of Imaging Studies (OASIS) and the Alzheimer Disease Neuroimaging Initiative (ADNI). Cleaning, merging, and preprocessing were completed using RStudio v1.3.1093. R-files can be found at https://github.com/dianahobbs/DataScience_OASIS.\n",
    "\n",
    "This dataset includes metrics for age, sex, education, race, APOE e4 status, PET- (amyloid and tau) and MR-Imaging (brain volume and thickness), and cognition in older adults that are cognitively unimpaired at baseline. Using this data, I will build a model that will learn from this data and predict individuals that present cognitive decline based on different biomarkers for AD.\n",
    "\n",
    "**YEARS OF DATA** \n",
    "\n",
    "***Select a Performance Measure\n",
    "We will use the Root Mean Square Error (RMSE). This is a typical performance measure for regression problems. It gives an idea of how much error the system typically makes in its predictions, with a higher weight for large errors.\n",
    "If we find many outlier districts, we may switch to mean absolute error, MAE, also called the average absolute deviation, before performing our model.**\n",
    "\n",
    "#### 2. Data Exploration \n",
    "- exploratory data analysis (EDA): visually explore the data. Look for correlations and patterns. \n",
    "We will perform a more focused look at the data later in the EDA step. For now, we just want a quick look to see what we've got.\n",
    "\n",
    "To this end, we'll do the following steps.\n",
    "\n",
    "Look at the head and tail of the data.\n",
    "Use .info() to get a basic description of the data; i.e., missing data, numerical v. categorical\n",
    "We see the following facts about the data.\n",
    "\n",
    "There are 20,640 instances in the dataset, which means that it is fairly small by Machine Learning standards, but it’s perfect to get started.\n",
    "The total_bedrooms attribute has only 20,433 nonnull values, meaning that 207 districts are missing this feature. We will need to take care of this later.\n",
    "All attributes are numerical, except the ocean_proximity field. Its type is object, so it could hold any kind of Python object. But since you loaded this data from a CSV file, you know that it must be a text attribute. When you looked at the top five rows, you probably noticed that the values in the ocean_proximity column were repetitive, which means that it is probably a categorical attribute.\n",
    "Let's look at the ocean_proximity column to find out what categories exist and how many districts belong to each category.\n",
    "\n",
    "Describe, histogram, etc etc etc and explain what they mean \n",
    "\n",
    "\n",
    "#### 3. Data Preparation \n",
    "- prepare the data for analysis\n",
    "\n",
    "create a test set & training set \n",
    "\n",
    "Explore again, but only explore the training set \n",
    "\n",
    "Make categorical variables numerical \n",
    "\n",
    "#### 4. Data Analysis \n",
    "- analyze the data: Choose the model you use for the question at hand\n",
    "\n",
    "train and evaluate the training set \n",
    "\n",
    "#### 5. Data Finetuning \n",
    "- fine tune the model: after your first attempt to analyzing the data, are there any improvements you can make? better tuning parameters? ensemble methods? \n",
    "\n",
    "#### 6. Data Conclusions \n",
    "- conclusions \n",
    "\n",
    "how did it do on the test set?? \n",
    "\n",
    "## Code\n",
    "not line by line, but give a high-level overview of how the code works. Describe any particularly tricky parts. \n",
    "\n",
    "## Project Takeaways \n",
    "conclusions, what did you learn? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd84f7-d727-4d66-83ec-3b86a143377f",
   "metadata": {},
   "source": [
    "# Make a separate file that just has the code alone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d8867a-a88d-4098-a357-2bf3af2d0879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
